{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in ./env/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jinja2>=2.9 in ./env/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: branca>=0.3.0 in ./env/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.6/site-packages (from folium)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./env/lib/python3.6/site-packages (from jinja2>=2.9->folium)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./env/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./env/lib/python3.6/site-packages (from requests->folium)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./env/lib/python3.6/site-packages (from requests->folium)\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe para Previsão de Pontos Críticos de Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "class HotspotPredictor(object):\n",
    "\n",
    "    def __init__(self, filepaths, n_clusters):\n",
    "\n",
    "        self._filepaths = filepaths\n",
    "        self._n_clusters = n_clusters\n",
    "        self._df = self._get_dataframe()\n",
    "        self._kmeans = self._get_kmeans()\n",
    "        self._hotspot = self._predict_hotspot()\n",
    "        self._boundaries = self._create_boundaries()\n",
    "        self._results = self._get_results()\n",
    "\n",
    "    def get_kmeans(self):\n",
    "        return self._kmeans\n",
    "\n",
    "    def get_regressor(self):\n",
    "        return self._regressor\n",
    "    \n",
    "    def get_n_clusters(self):\n",
    "        return self._n_clusters\n",
    "\n",
    "    def get_df(self):\n",
    "        return self._df\n",
    "\n",
    "    def get_hotspot(self):\n",
    "        return self._hotspot\n",
    "\n",
    "    def get_boundaries(self):\n",
    "        return self._boundaries\n",
    "\n",
    "    def save_kmeans_to(self, address):\n",
    "        dump(self._kmeans, address)\n",
    "\n",
    "    def get_results(self):\n",
    "        return self._results\n",
    "\n",
    "    def _get_kmeans(self):\n",
    "        if self._n_clusters == 0:\n",
    "            init_clusters = self._df[['BAIRRO', 'CIDADE', 'LATITUDE', 'LONGITUDE']].groupby(\n",
    "                ['CIDADE', 'BAIRRO']).mean().dropna().to_numpy()\n",
    "            self._n_clusters, _ = init_clusters.shape\n",
    "            return MiniBatchKMeans(n_clusters=self._n_clusters, init_size=self._n_clusters, max_iter=10000,\n",
    "                                   init=init_clusters)\n",
    "        else:\n",
    "            return MiniBatchKMeans(n_clusters=self._n_clusters, init_size=self._n_clusters, max_iter=10000)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_dataframe(filepath, month):\n",
    "        cols = ['DATAOCORRENCIA', 'HORAOCORRENCIA', 'BAIRRO', 'CIDADE', 'LATITUDE', 'LONGITUDE']\n",
    "        df = pd.read_csv(\n",
    "            filepath_or_buffer=filepath,\n",
    "            encoding='utf-16 le',\n",
    "            delimiter='\\t',\n",
    "            decimal=',',\n",
    "            dayfirst=True,\n",
    "            usecols=cols\n",
    "        )\n",
    "        df['MES'] = month\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _clear_dataframe(df):\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df['LATITUDE'] = pd.to_numeric(df['LATITUDE'], errors='coerce')\n",
    "        df['LONGITUDE'] = pd.to_numeric(df['LONGITUDE'], errors='coerce')\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def _get_dataframe(self):\n",
    "        df = pd.concat([self._load_dataframe(filepath, idx + 1) for idx, filepath in enumerate(self._filepaths)])\n",
    "        return self._clear_dataframe(df)\n",
    "\n",
    "    def _process_dataframe(self, df):\n",
    "        df['GRUPO'] = self._kmeans.fit_predict(df[['LATITUDE', 'LONGITUDE']])\n",
    "        df = df.groupby(['GRUPO', 'MES']).size().reset_index()\n",
    "        df.columns = ['GRUPO', 'MES', 'COUNT']\n",
    "\n",
    "        pipeline = ColumnTransformer([\n",
    "            ('grupo', OneHotEncoder(categories=[np.arange(self._n_clusters, dtype='int32')]), ['GRUPO']),\n",
    "            ('mes', 'passthrough', ['MES'])\n",
    "        ])\n",
    "        X = pipeline.fit_transform(df)\n",
    "        y = df['COUNT']\n",
    "        return X, y\n",
    "\n",
    "    def _predict_hotspot(self):\n",
    "        X_train, y_train = self._process_dataframe(self._df)\n",
    "        threshold = y_train.median()\n",
    "\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        X_pred = np.c_[np.identity(self._n_clusters), np.ones(self._n_clusters) * (len(self._filepaths) + 1)]\n",
    "        y_pred = lr.predict(X_pred) >= threshold\n",
    "        self._regressor = lr\n",
    "\n",
    "        hotspot = dict()\n",
    "        for i in range(self._n_clusters):\n",
    "            hotspot[i] = y_pred[i]\n",
    "        return hotspot\n",
    "\n",
    "    def _get_results(self):\n",
    "        results = []\n",
    "        for cluster in range(self._n_clusters):\n",
    "            df = self._df[self._df['GRUPO'] == cluster]\n",
    "            features = [self._get_point(row['LATITUDE'], row['LONGITUDE'], row['DATAOCORRENCIA'], row['HORAOCORRENCIA'],\n",
    "                                        cluster) for idx, row in df.iterrows()]\n",
    "            features.append(self._get_boundary(cluster))\n",
    "            results.append(self._get_feature_collection(features, cluster))\n",
    "        return results\n",
    "\n",
    "    def _get_point(self, latitude, longitude, date, time, cluster):\n",
    "        return {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'Point',\n",
    "                'coordinates': [latitude, longitude]\n",
    "            },\n",
    "            'properties': {\n",
    "                'date': date,\n",
    "                'time': time\n",
    "            },\n",
    "            'hotspot': bool(self._hotspot[cluster]),\n",
    "            'cluster': cluster\n",
    "        }\n",
    "\n",
    "    def _get_boundary(self, cluster):\n",
    "        return {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'LineString',\n",
    "                'coordinates': self._boundaries.get(cluster, [])\n",
    "            },\n",
    "            'hotspot': bool(self._hotspot[cluster]),\n",
    "            'cluster': cluster\n",
    "        }\n",
    "\n",
    "    def _get_feature_collection(self, features, cluster):\n",
    "        return {\n",
    "            'type': 'FeatureCollection',\n",
    "            'features': features,\n",
    "            'hotspot': bool(self._hotspot[cluster]),\n",
    "            'cluster': cluster\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "        if vor.points.shape[1] != 2:\n",
    "            raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "        new_regions = []\n",
    "        new_vertices = vor.vertices.tolist()\n",
    "\n",
    "        center = vor.points.mean(axis=0)\n",
    "        if radius is None:\n",
    "            radius = vor.points.ptp().max() * 2\n",
    "\n",
    "        all_ridges = {}\n",
    "        for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "            all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "            all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "\n",
    "        for p1, region in enumerate(vor.point_region):\n",
    "            vertices = vor.regions[region]\n",
    "\n",
    "            if all([v >= 0 for v in vertices]):\n",
    "                new_regions.append(vertices)\n",
    "                continue\n",
    "\n",
    "            ridges = all_ridges.get(p1, [])\n",
    "            new_region = [v for v in vertices if v >= 0]\n",
    "\n",
    "            for p2, v1, v2 in ridges:\n",
    "                if v2 < 0:\n",
    "                    v1, v2 = v2, v1\n",
    "                if v1 >= 0:\n",
    "                    continue\n",
    "\n",
    "                t = vor.points[p2] - vor.points[p1]\n",
    "                t /= np.linalg.norm(t)\n",
    "                n = np.array([-t[1], t[0]])\n",
    "\n",
    "                midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "                direction = np.sign(np.dot(midpoint - center, n)) * n\n",
    "                far_point = vor.vertices[v2] + direction * radius\n",
    "\n",
    "                new_region.append(len(new_vertices))\n",
    "                new_vertices.append(far_point.tolist())\n",
    "\n",
    "            vs = np.asarray([new_vertices[v] for v in new_region])\n",
    "            c = vs.mean(axis=0)\n",
    "            angles = np.arctan2(vs[:, 1] - c[1], vs[:, 0] - c[0])\n",
    "            new_region = np.array(new_region)[np.argsort(angles)]\n",
    "            new_regions.append(new_region.tolist())\n",
    "\n",
    "        return new_regions, np.asarray(new_vertices)\n",
    "\n",
    "    def _create_boundaries(self):\n",
    "        boundaries = {}\n",
    "        points = self._kmeans.cluster_centers_\n",
    "        clusters = self._kmeans.predict(points)\n",
    "        vor = Voronoi(points)\n",
    "        regions, vertices = self.voronoi_finite_polygons_2d(vor)\n",
    "        for cluster, region in zip(clusters, regions):\n",
    "            boundaries[cluster] = vertices[region].tolist()\n",
    "        return boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe para Visualização dos Pontos Críticos de Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "class HotspotViewer(object):\n",
    "\n",
    "    def __init__(self, clusters_data, location=(-23.5489, -46.6388)):\n",
    "        self._clusters_data = clusters_data\n",
    "        self.folium_map = folium.Map(location=location, zoom_start=12, zoom_control=True, prefer_canvas=True)\n",
    "        circles, polygons = self._get_data()\n",
    "        self.folium_map.add_child(polygons)\n",
    "        self.folium_map.add_child(circles)\n",
    "\n",
    "    def get_result(self):\n",
    "        return self.folium_map\n",
    "\n",
    "    def save_map_to(self, address):\n",
    "        with open(address, 'w') as f:\n",
    "            f.write(self.folium_map._repr_html_())\n",
    "\n",
    "    def _get_data(self):\n",
    "        circles = folium.FeatureGroup(name='Circles')\n",
    "        polygons = folium.FeatureGroup(name='Polygons')\n",
    "        for data in self._clusters_data:\n",
    "            features = data['features']\n",
    "            for feature in features:\n",
    "                if feature['geometry']['type'] == 'Point':\n",
    "                    date = feature['properties']['date']\n",
    "                    time = feature['properties']['time']\n",
    "                    location = feature['geometry']['coordinates']\n",
    "                    circles.add_child(self._new_circle(date, time, location))\n",
    "                elif feature['geometry']['type'] == 'LineString':\n",
    "                    hotspot = feature['hotspot']\n",
    "                    locations = feature['geometry']['coordinates']\n",
    "                    if locations:\n",
    "                        polygons.add_child(self._new_polygon(locations, hotspot))\n",
    "        return circles, polygons\n",
    "\n",
    "    @staticmethod\n",
    "    def _new_circle(date, time, location):\n",
    "        return folium.Circle(\n",
    "            location=location,\n",
    "            popup='Data: {0}\\nHora: {1}'.format(date, time),\n",
    "            color='red',\n",
    "            radius=10,\n",
    "            fill=True\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _new_polygon(locations, hotspot):\n",
    "        return folium.Polygon(\n",
    "            locations=locations,\n",
    "            fill_color='red' if hotspot else 'green',\n",
    "            fill_opacity=0.2,\n",
    "            color='black',\n",
    "            weight=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando a Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Setembro, Outubro, Novembro e Dezembro de 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\n",
    "    'data/DadosBO_2019_9(ROUBO DE CELULAR).xls',\n",
    "    'data/DadosBO_2019_10(ROUBO DE CELULAR).xls',\n",
    "    'data/DadosBO_2019_11(ROUBO DE CELULAR).xls',\n",
    "    'data/DadosBO_2019_12(ROUBO DE CELULAR).xls',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetos para previsão dos Pontos Críticos de Crimes, com 2000 agrupamentos e com agrupamento dinâmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akumaex/Documentos/MAC0499/jupyter/env/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py:1600: RuntimeWarning: Explicit initial center position passed: performing only one init in MiniBatchKMeans instead of n_init=3.\n",
      "  super()._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "defined = HotspotPredictor(filepaths, 2000)\n",
    "dynamic = HotspotPredictor(filepaths, 0)\n",
    "defined_results = defined.get_results()\n",
    "dynamic_results = dynamic.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetos para visualização dos Pontos Críticos de Crimes para a região metropolitana e interior de São Paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_sao_paulo = HotspotViewer(defined_results).get_result()\n",
    "dynamic_sao_paulo = HotspotViewer(dynamic_results).get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos resultados dos modelos com número definido de agrupamentos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "defined_sao_paulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos resultados dos modelos com número dinâmico de agrupamentos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dynamic_sao_paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
